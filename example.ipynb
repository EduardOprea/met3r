{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use MEt3R with MASt3R "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from met3r import MEt3R\n",
    "\n",
    "IMG_SIZE = 256\n",
    "\n",
    "# Initialize MEt3R\n",
    "metric = MEt3R(\n",
    "    img_size=IMG_SIZE, # Default, set to `None` to use the input resolution on the fly!\n",
    "    use_norm=True, # Default \n",
    "    backbone=\"mast3r\", # Default, select from [\"mast3r\", \"dust3r\", \"raft\"]\n",
    "    feature_backbone=\"dino16\", # Default, select from [\"dino16\", \"dinov2\", \"maskclip\", \"vit\", \"clip\", \"resnet50\"]\n",
    "    feature_backbone_weights=\"mhamilton723/FeatUp\", # Default\n",
    "    upsampler='featup', # Default, select from [\"featup\", \"nearest\", \"bilinear\", \"bicubic\"]\n",
    "    distance=\"cosine\", # Default, [\"cosine\", \"lpips\", \"rmse\", \"psnr\", \"mse\", \"ssim\"]\n",
    "    freeze=True, # Default\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare inputs of shape (batch, views, channels, height, width): views must be 2\n",
    "# RGB range must be in [-1, 1]\n",
    "# Reduce the batch size in case of CUDA OOM\n",
    "inputs = torch.randn((10, 2, 3, IMG_SIZE, IMG_SIZE)).cuda()\n",
    "inputs = inputs.clip(-1, 1)\n",
    "\n",
    "# Evaluate MEt3R\n",
    "score, *_ = metric(\n",
    "    images=inputs, \n",
    "    return_overlap_mask=False, # Default \n",
    "    return_score_map=False, # Default \n",
    "    return_projections=False # Default \n",
    ")\n",
    "\n",
    "# Should be between 0.22 - 0.29\n",
    "print(score.mean().item())\n",
    "\n",
    "# Clear up GPU memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use MEt3R with DUSt3R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from met3r import MEt3R\n",
    "\n",
    "IMG_SIZE = 256\n",
    "\n",
    "# Initialize MEt3R\n",
    "metric = MEt3R(\n",
    "    img_size=IMG_SIZE,\n",
    "    use_norm=True,\n",
    "    backbone=\"dust3r\",\n",
    "    feature_backbone=\"dino16\",\n",
    "    feature_backbone_weights=\"mhamilton723/FeatUp\",\n",
    "    upsampler=\"featup\",\n",
    "    distance=\"cosine\",\n",
    "    freeze=True, \n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare inputs of shape (batch, views, channels, height, width): views must be 2\n",
    "# RGB range must be in [-1, 1]\n",
    "# Reduce the batch size in case of CUDA OOM\n",
    "inputs = torch.randn((10, 2, 3, IMG_SIZE, IMG_SIZE)).cuda()\n",
    "inputs = inputs.clip(-1, 1)\n",
    "\n",
    "# Evaluate MEt3R\n",
    "score, *_ = metric(\n",
    "    images=inputs, \n",
    "    return_overlap_mask=False, # Default \n",
    "    return_score_map=False, # Default \n",
    "    return_projections=False # Default \n",
    ")\n",
    "\n",
    "# Should be between 0.30 - 0.35\n",
    "print(score.mean().item())\n",
    "\n",
    "# Clear up GPU memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use MEt3R with RAFT (Optical Flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from met3r import MEt3R\n",
    "\n",
    "IMG_SIZE = 256\n",
    "\n",
    "# Initialize MEt3R\n",
    "metric = MEt3R(\n",
    "    img_size=IMG_SIZE,\n",
    "    use_norm=True, \n",
    "    backbone=\"raft\",\n",
    "    feature_backbone=\"dino16\",\n",
    "    feature_backbone_weights=\"mhamilton723/FeatUp\",\n",
    "    upsampler=\"featup\",\n",
    "    distance=\"cosine\",\n",
    "    freeze=True, \n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare inputs of shape (batch, views, channels, height, width): views must be 2\n",
    "# RGB range must be in [-1, 1]\n",
    "# Reduce the batch size in case of CUDA OOM\n",
    "inputs = torch.randn((10, 2, 3, IMG_SIZE, IMG_SIZE)).cuda()\n",
    "inputs = inputs.clip(-1, 1)\n",
    "\n",
    "# Evaluate MEt3R\n",
    "score, *_ = metric(\n",
    "    images=inputs, \n",
    "    return_overlap_mask=False, # Default \n",
    "    return_score_map=False, # Default \n",
    "    return_projections=False # Default \n",
    ")\n",
    "\n",
    "# Should be between 0.17 - 0.18\n",
    "print(score.mean().item())\n",
    "\n",
    "# Clear up GPU memory\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "met3r",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
